{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "#for interactive 3d plot \n",
    "!pip install PrettyTable > /dev/null 2>&1\n",
    "from prettytable import PrettyTable\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "import enum\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# import ipyvolume as ipv\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "# trainFile = 'trainNN.txt'\n",
    "# testFile = 'testNN.txt'\n",
    "\n",
    "train_dataset_file = 'vectorized_dataset_train.csv'\n",
    "test_dataset_file = 'vectorized_dataset_test.csv'\n",
    "dev_dataset_file = 'vectorized_dataset_dev.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 19998) (5500, 19998) (2200, 19998)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_dataset_file, header = None)\n",
    "df_test = pd.read_csv(test_dataset_file, header = None)\n",
    "df_dev = pd.read_csv(dev_dataset_file, header = None)\n",
    "\n",
    "x_train, y_train = df_train.iloc[:,:-1], df_train.iloc[:,-1]\n",
    "x_test, y_test = df_test.iloc[:,:-1], df_test.iloc[:,-1]\n",
    "x_dev, y_dev = df_dev.iloc[:,:-1], df_dev.iloc[:,-1]\n",
    "# x_test, y_test = train_test_split(X,Y, test_size = 500/(700+500) ) \n",
    "# x_dev, y_dev = train_test_split(x_train,y_train, test_size = 200/(500+200) )\n",
    "print(x_train.shape, x_test.shape, x_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def castToType(x):\n",
    "    try:\n",
    "        return x.astype('float').astype('Int64') #pd 0.24+ \n",
    "    except:\n",
    "        try:\n",
    "            return x.astype('float')\n",
    "        except:\n",
    "            return x\n",
    "\n",
    "def get_binarize_matrix(mat):\n",
    "    tmp = np.copy(mat)\n",
    "    tmp[tmp>0] = 1 \n",
    "    return tmp \n",
    "\n",
    "\n",
    "class DataManager:\n",
    "    def __init_(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.df = df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "        self.df.replace(r'^[\\s?]*$', np.nan, regex=True, inplace = True)\n",
    "        self.df = self.df.apply(castToType)\n",
    "\n",
    "    def get_handled_missing_values(self, nullThreshold = 0.7):\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].isnull().any() :\n",
    "                if np.issubdtype(self.df[col].dtype, np.number):\n",
    "                    self.df[col] = self.df[col].fillna(self.df[col].mean())\n",
    "        \n",
    "        \n",
    "        self.df.dropna(thresh=self.df.shape[0]*nullThreshold,how='all',axis=1, inplace= True)\n",
    "        self.df.dropna(axis = 0, inplace = True)\n",
    "        \n",
    "        return self.df\n",
    "\n",
    "    def get_normalized_values(self):\n",
    "        for i in range(len(self.df.columns)-1):\n",
    "            self.df[:, i] = (self.df[:, i] - np.mean(self.df[:,i]))/np.std(self.df[:,i])\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def get_data_after_removed_cols(self):\n",
    "        for col in self.df.columns:\n",
    "            if len(self.df[col].unique()) == 1:\n",
    "                print(col)\n",
    "                df = self.df.drop(col,axis=1)\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            if len(self.df[col].unique()) == len(self.df[col]):\n",
    "                print(col)\n",
    "                df = self.df.drop(col,inplace=True,axis=1)\n",
    "        return df \n",
    "    \n",
    "    def get_one_hot_encoded(df_column):\n",
    "        from sklearn.preprocessing import LabelEncoder \n",
    "        from sklearn.preprocessing import OneHotEncoder \n",
    "        enc = OneHotEncoder(sparse=False, categories='auto')\n",
    "        \n",
    "        df_column = enc.fit_transform(df_column.reshape(len(df_column), -1))\n",
    "        \n",
    "        return df_column\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod \n",
    "\n",
    "class Distance:\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, instance1, instance2):\n",
    "        pass\n",
    "\n",
    "#Distance calculation between two data points\n",
    "class EuclideanDistance(Distance):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, instance1, instance2):\n",
    "        instance1 = np.array(instance1)\n",
    "        instance2 = np.array(instance2)\n",
    "        return np.sqrt(np.sum((instance1 - instance2)**2) )\n",
    "\n",
    "class HammingDistance(Distance):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, instance1, instance2):\n",
    "        instance1 = np.array(instance1)\n",
    "        instance2 = np.array(instance2)\n",
    "        return np.sum(np.abs(instance1 - instance2)) \n",
    "    \n",
    "class CosineSimilarity(Distance):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, instance1, instance2):\n",
    "        instance1 = np.array(instance1)\n",
    "        instance2 = np.array(instance2)\n",
    "        return 1 - np.dot(instance1, instance2)/(np.linalg.norm(instance1)*np.linalg.norm(instance2))\n",
    "\n",
    "\n",
    "class DISTANCE_ENUM(str, enum.Enum): \n",
    "    EUCLIDEAN = \"euclidean\"\n",
    "    COSINE = \"cosine\"\n",
    "    HAMMING = \"hamming\"\n",
    "    \n",
    "\n",
    "def get_distance(distance_func):\n",
    "    if distance_func == DISTANCE_ENUM.EUCLIDEAN:\n",
    "        return EuclideanDistance()\n",
    "    elif distance_func == DISTANCE_ENUM.COSINE:\n",
    "        return CosineSimilarity()\n",
    "    elif distance_func == DISTANCE_ENUM.HAMMING:\n",
    "        return HammingDistance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class KNN:\n",
    "\n",
    "    def __init__(self, n_neighbors = 3, weights='uniform', distance_func = 'cosine'):\n",
    "        self.x_train = None\n",
    "        self.y_train = None\n",
    "        self.num_class = None\n",
    "        self.weights = weights\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.distance_func_name = distance_func\n",
    "        self.distance_func = get_distance(distance_func)\n",
    "        self.total_train_data = 0\n",
    "        self.x_train_tf_idf = []\n",
    "        self.word_present_in_num_documents = []\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = np.array(x_train, dtype='O')\n",
    "        self.y_train = np.array(y_train, dtype='O')\n",
    "        self.num_class = len(set(y_train))\n",
    "        self.total_train_data = len(x_train) * 1.0\n",
    "        x_train = np.array(x_train, dtype='O')\n",
    "        x_train[x_train > 0] = 1\n",
    "        self.word_present_in_num_documents = np.sum(x_train, axis=0) * 1.0\n",
    "        self.x_train_tf_idf = self.get_TF_IDF(self.x_train)\n",
    "        \n",
    "    def get_TF_IDF(self, X_mat):\n",
    "        tf = np.array(X_mat)\n",
    "        tf = tf / tf.sum(axis=1, keepdims=True)\n",
    "        idf = np.log(np.array(self.total_train_data / (self.word_present_in_num_documents + 1), dtype=float)  ) \n",
    "        return tf * idf \n",
    "        \n",
    "    def predict(self, x_test):        \n",
    "        allPredictedOutputs =[]\n",
    "        x_test = np.array(x_test)\n",
    "        distance_matrix = []\n",
    "        if self.distance_func_name == DISTANCE_ENUM.COSINE:\n",
    "            test_tf_idf = self.get_TF_IDF(x_test)\n",
    "            distance_matrix = metrics.pairwise_distances(self.x_train_tf_idf, test_tf_idf, metric=self.distance_func_name )\n",
    "        elif self.distance_func_name == DISTANCE_ENUM.HAMMING:\n",
    "            distance_matrix = metrics.pairwise_distances(get_binarize_matrix(self.x_train),get_binarize_matrix(x_test), metric=self.distance_func_name )\n",
    "        else:\n",
    "            distance_matrix = metrics.pairwise_distances(self.x_train, x_test, metric=self.distance_func_name)\n",
    "\n",
    "        #calculate for earch test data points\n",
    "        for sample_no in range(len(x_test)):\n",
    "\n",
    "            allDistances = np.vstack(\n",
    "                (self.y_train,\n",
    "                distance_matrix[:,sample_no])\n",
    "            ).T\n",
    "            \n",
    "\n",
    "            allDistances = allDistances[allDistances[:,-1].argsort()] \n",
    "\n",
    "\n",
    "            #Assuming output labels are from 0 to uniqueOutputCount-1\n",
    "            voteCount = dict()\n",
    "            neighbors = []\n",
    "            for i in range(self.n_neighbors):\n",
    "                voting_weight = 1.0 / ( allDistances[i][1] + 1e-8 )  # 1 / distance \n",
    "                class_label = int(allDistances[i][0])\n",
    "                voteCount[class_label] = voting_weight if class_label not in voteCount else voteCount[class_label] + voting_weight\n",
    "                \n",
    "            #Determine the Majority Voting (Equal weight considered)\n",
    "            mxCnt, mxClass = 0, 0\n",
    "            for key in voteCount:\n",
    "                if voteCount[key] > mxCnt:\n",
    "                    mxCnt, mxClass = voteCount[key] , key\n",
    "\n",
    "            allPredictedOutputs.append(mxClass)\n",
    "        return allPredictedOutputs   #, allTestNeighbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTANCE_ENUM.EUCLIDEAN 1 57.45454545454546\n",
      "DISTANCE_ENUM.EUCLIDEAN 3 57.77272727272727\n",
      "DISTANCE_ENUM.EUCLIDEAN 5 56.54545454545455\n",
      "DISTANCE_ENUM.COSINE 1 81.22727272727272\n",
      "DISTANCE_ENUM.COSINE 3 83.45454545454545\n",
      "DISTANCE_ENUM.COSINE 5 83.5\n",
      "DISTANCE_ENUM.HAMMING 1 39.86363636363636\n",
      "DISTANCE_ENUM.HAMMING 3 41.27272727272727\n",
      "DISTANCE_ENUM.HAMMING 5 40.54545454545455\n",
      "83.5 5 DISTANCE_ENUM.COSINE\n"
     ]
    }
   ],
   "source": [
    "t = PrettyTable(['Method', 'K', 'Accuracy'])\n",
    "\n",
    "best_distance_func = ''\n",
    "best_k_in_Knn = 1\n",
    "best_accuracy = 0\n",
    "\n",
    "for dist_func in DISTANCE_ENUM:\n",
    "    for k in [1,3,5]:\n",
    "        model = KNN(n_neighbors = k, distance_func = dist_func)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_dev)\n",
    "        accuracy = metrics.accuracy_score(y_dev, y_pred) * 100\n",
    "        print(dist_func, k,  accuracy)\n",
    "        \n",
    "        if accuracy >  best_accuracy:\n",
    "            best_distance_func, best_k_in_Knn = dist_func, k\n",
    "            best_accuracy = accuracy\n",
    "        t.add_row([dist_func, k,  accuracy])\n",
    "            \n",
    "\n",
    "print(best_accuracy, best_k_in_Knn, best_distance_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1505014_report.txt', 'w') as f:\n",
    "    f.write('KNN\\n' )\n",
    "    f.write('Accurary for Validation set\\n')\n",
    "    f.write(t.get_string())\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        \n",
    "def getReplacedList(y):\n",
    "        class_list = list(set(sorted(y)))\n",
    "\n",
    "        class_dict_transform = {}\n",
    "\n",
    "        i = 0\n",
    "        for original_class in class_list:\n",
    "            class_dict_transform[original_class] = i\n",
    "            i+=1\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            y[i] = class_dict_transform[y[i]]\n",
    "        return y\n",
    "\n",
    "class NaiveBayes:\n",
    "\n",
    "    def __init__(self, smoothing_factor = 1.0):\n",
    "\n",
    "        self.class_list = None\n",
    "        self.n = 0 \n",
    "        self.classwise_summary = []\n",
    "        self.class_frequency = []\n",
    "        self.num_feature = 0\n",
    "        self.smoothing_factor = float(smoothing_factor)\n",
    "\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        self.n = len(x_train) * 1.0\n",
    "        self.num_feature = len(x_train[0]) \n",
    "        self.class_list = list(set(sorted(y_train))) \n",
    "        y_train = getReplacedList(y_train)\n",
    "        \n",
    "        classwise_mat = [ [] for _ in range (len(self.class_list)) ]    # 2d matrix grouped by classes \n",
    "        self.class_frequency = [ 0 ] * len(self.class_list)\n",
    "        \n",
    "        \n",
    "        for x,y in zip(x_train, y_train):\n",
    "            classwise_mat[y].append(x)\n",
    "            self.class_frequency[y] += 1\n",
    "        \n",
    "        self.class_frequency = np.array(self.class_frequency) / self.n * 100.0\n",
    "        \n",
    "        self.P_w_given_Class = []\n",
    "        \n",
    "        total_word_in_entire_train = np.sum(x_train)\n",
    "        \n",
    "        for class_label in range(len(self.class_list)):\n",
    "            \n",
    "            mat = np.array(classwise_mat[class_label])\n",
    "            total_words_under_class = np.sum(mat) \n",
    "            self.P_w_given_Class.append( np.sum(mat, axis=0) + self.smoothing_factor / \\\n",
    "                            (total_words_under_class + self.smoothing_factor * total_word_in_entire_train ) )\n",
    "        \n",
    "    def predict(self, x_test): \n",
    "        y_pred = []\n",
    "        x_test_binary = np.copy(x_test)\n",
    "        x_test_binary[x_test_binary > 0] = 1.0\n",
    "#         print(self.class_frequency.shape)\n",
    "        for i in range(len(x_test_binary)):\n",
    "            x = x_test_binary[i,:].reshape(1, self.num_feature)\n",
    "            P_Dt_given_class = x * self.P_w_given_Class \n",
    "\n",
    "#             cnt = np.count_nonzero(x!=0)\n",
    "#             P_Dt_given_class = P_Dt_given_class[P_Dt_given_class!=0].reshape(-1,cnt)\n",
    "            P_Dt_given_class[ P_Dt_given_class == 0 ] = 1\n",
    "            P_Dt_given_class = np.prod(P_Dt_given_class, axis = 1)\n",
    "            posterior_prob = self.class_frequency * P_Dt_given_class\n",
    "            pred_class = np.argmax(posterior_prob )\n",
    "            \n",
    "            y_pred.append(self.class_list[pred_class])\n",
    "\n",
    "        return y_pred     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 84.31818181818181\n",
      "0.2 84.27272727272728\n",
      "0.30000000000000004 84.36363636363636\n",
      "0.4 84.36363636363636\n",
      "0.5 84.36363636363636\n",
      "0.6 84.36363636363636\n",
      "0.7000000000000001 84.31818181818181\n",
      "0.8 84.31818181818181\n",
      "0.9 84.31818181818181\n",
      "1.0 84.31818181818181\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "t = PrettyTable(['SF', 'Accuracy'])\n",
    "\n",
    "best_sf_naive = 1\n",
    "best_accuracy = 0\n",
    "\n",
    "for sf in np.linspace(0.1, 1, num=10):\n",
    "    model = NaiveBayes(smoothing_factor=sf)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_dev)\n",
    "    accuracy = metrics.accuracy_score(y_dev, y_pred) * 100\n",
    "    print(sf,  accuracy)\n",
    "    \n",
    "    if accuracy >  best_accuracy:\n",
    "        best_sf_naive = sf\n",
    "        best_accuracy = accuracy\n",
    "    t.add_row([sf, accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1505014_report.txt', 'a') as f:\n",
    "    f.write('Naive Bayes\\n' )\n",
    "    f.write('Accurary for Validation set\\n')\n",
    "    f.write(t.get_string())\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data accuracy with best hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ara):\n",
    "    return pd.DataFrame(np.array(ara)).describe().loc[['min','max', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 DISTANCE_ENUM.COSINE\n",
      "100.0\n",
      "100.0\n",
      "90.0\n",
      "70.0\n",
      "80.0\n",
      "80.0\n",
      "50.0\n",
      "50.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "80.0\n",
      "60.0\n",
      "80.0\n",
      "100.0\n",
      "90.0\n",
      "90.0\n",
      "70.0\n",
      "60.0\n",
      "90.0\n",
      "100.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "80.0\n",
      "90.0\n",
      "70.0\n",
      "90.0\n",
      "70.0\n",
      "80.0\n",
      "90.0\n",
      "70.0\n",
      "100.0\n",
      "90.0\n",
      "80.0\n",
      "80.0\n",
      "80.0\n",
      "70.0\n",
      "100.0\n",
      "60.0\n",
      "90.0\n",
      "70.0\n",
      "70.0\n",
      "70.0\n",
      "80.0\n",
      "90.0\n",
      "60.0\n",
      "70.0\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "num_test_iterations = 50\n",
    "knn_test_accuracies = []\n",
    "\n",
    "t = PrettyTable(['Iteration No', 'Accuracy'])\n",
    "print( best_k_in_Knn, best_distance_func)\n",
    "model = KNN(n_neighbors = best_k_in_Knn, distance_func = best_distance_func)\n",
    "model.fit(x_train, y_train)\n",
    "for i in range(num_test_iterations):\n",
    "\n",
    "    y_pred = model.predict(x_test.iloc[i*10:(i+1)*10, :])\n",
    "    accuracy = metrics.accuracy_score(y_test.iloc[i*10:(i+1)*10], y_pred) * 100\n",
    "    print(accuracy)\n",
    "    knn_test_accuracies.append(accuracy)\n",
    "    t.add_row([i,  accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1505014_report.txt', 'a') as f:\n",
    "    f.write('KNN\\n' )\n",
    "    f.write('Accurary for Test set\\n')\n",
    "    f.write(t.get_string())\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best smoothing factor  0.30000000000000004\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "80.0\n",
      "90.0\n",
      "80.0\n",
      "80.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\torch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n",
      "90.0\n",
      "100.0\n",
      "80.0\n",
      "90.0\n",
      "60.0\n",
      "100.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "100.0\n",
      "100.0\n",
      "90.0\n",
      "100.0\n",
      "100.0\n",
      "90.0\n",
      "80.0\n",
      "90.0\n",
      "80.0\n",
      "80.0\n",
      "100.0\n",
      "90.0\n",
      "60.0\n",
      "90.0\n",
      "90.0\n",
      "100.0\n",
      "90.0\n",
      "80.0\n",
      "100.0\n",
      "90.0\n",
      "80.0\n",
      "90.0\n",
      "80.0\n",
      "70.0\n",
      "90.0\n",
      "70.0\n",
      "80.0\n",
      "80.0\n",
      "100.0\n",
      "90.0\n",
      "70.0\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "num_test_iterations = 50\n",
    "naive_test_accuracies = []\n",
    "\n",
    "t = PrettyTable(['Iteration No', 'Accuracy'])\n",
    "print('Best smoothing factor ', best_sf_naive)\n",
    "model = NaiveBayes(smoothing_factor=best_sf_naive)\n",
    "model.fit(x_train, y_train)\n",
    "for i in range(num_test_iterations):\n",
    "\n",
    "    y_pred = model.predict(x_test.iloc[i*10:(i+1)*10, :])\n",
    "    accuracy = metrics.accuracy_score(y_test.iloc[i*10:(i+1)*10], y_pred) * 100\n",
    "    print(accuracy)\n",
    "    naive_test_accuracies.append(accuracy)\n",
    "    t.add_row([i,  accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1505014_report.txt', 'a') as f:\n",
    "    f.write('Naive Bayes\\n' )\n",
    "    f.write('Accurary for Test set\\n')\n",
    "    f.write(t.get_string())\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-3.6421413166111147, pvalue=0.0006515010281061904)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(knn_test_accuracies,naive_test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.192453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "min   50.000000\n",
       "max  100.000000\n",
       "std   13.192453"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(knn_test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.631106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "min   60.000000\n",
       "max  100.000000\n",
       "std   10.631106"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(naive_test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neigh.predict(x_test)\n",
    "# print(metrics.accuracy_score(y_test,neigh.predict(x_test)) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = {'4': 'ac', '34':'45'}\n",
    "# lst = [4,5,34,5,55,5,4]\n",
    "# class_list = list(set(sorted(lst)))\n",
    "\n",
    "# tmp = getReplacedList(lst)\n",
    "\n",
    "# lst2 = [3,1,1,1,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
